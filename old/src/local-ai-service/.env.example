# Ollama Configuration
OLLAMA_BASE_URL=http://localhost:11434
OLLAMA_MODEL=mistral

# Service Configuration
HOST=127.0.0.1
PORT=8000
LOG_LEVEL=INFO

# Embedding Model
EMBEDDING_MODEL=all-MiniLM-L6-v2

# spaCy Model (download with: python -m spacy download en_core_web_sm)
SPACY_MODEL=en_core_web_sm